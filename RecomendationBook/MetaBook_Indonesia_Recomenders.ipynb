{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27936c3d77ca435bbbdc8a1f8467996c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9db96d69fb2f4159b257bb2b20f517df",
              "IPY_MODEL_ce040ed3088e477c8cea9db03a26066f",
              "IPY_MODEL_973df260183142d2ae0d338342756d99"
            ],
            "layout": "IPY_MODEL_ee26f7004709436db16799c082eea0dd"
          }
        },
        "9db96d69fb2f4159b257bb2b20f517df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac92366fa41440bda19ce182562b32f3",
            "placeholder": "​",
            "style": "IPY_MODEL_4394e94f4de44c5582169277582b7cf8",
            "value": "100%"
          }
        },
        "ce040ed3088e477c8cea9db03a26066f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96fdc78170ae46ba8ad0dbd2848304ba",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df57b1aa7ff2498a97f73b1c478d1326",
            "value": 50
          }
        },
        "973df260183142d2ae0d338342756d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04462b275dfc40e4ad9e953eddfa8c03",
            "placeholder": "​",
            "style": "IPY_MODEL_cea1c45cbf29457f9acf8af5d3eeddc9",
            "value": " 50/50 [00:01&lt;00:00, 32.88it/s]"
          }
        },
        "ee26f7004709436db16799c082eea0dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac92366fa41440bda19ce182562b32f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4394e94f4de44c5582169277582b7cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96fdc78170ae46ba8ad0dbd2848304ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df57b1aa7ff2498a97f73b1c478d1326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04462b275dfc40e4ad9e953eddfa8c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea1c45cbf29457f9acf8af5d3eeddc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccGVOvoYCfLq",
        "outputId": "00f31f4c-d283-45ff-f9aa-e436a5c0586b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnu0vcPWL8P6",
        "outputId": "bb1eeb75-ac80-49ab-9cd6-4afbffc1ca78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.6.2)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-recommenders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LikTSC2FPWAl",
        "outputId": "9d851593-530f-4273-8a84-08e1bcf80a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-recommenders\n",
            "  Downloading tensorflow_recommenders-0.7.3-py3-none-any.whl (96 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/96.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-recommenders) (1.4.0)\n",
            "Requirement already satisfied: tensorflow>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-recommenders) (2.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->tensorflow-recommenders) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->tensorflow-recommenders) (3.2.2)\n",
            "Installing collected packages: tensorflow-recommenders\n",
            "Successfully installed tensorflow-recommenders-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFuia8qdQQ2N",
        "outputId": "4eb6f361-3c46-432f-c9b8-bf21c0d53c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V_w5eqGqQgh2",
        "outputId": "38bdde92-8f66-43b0-c996-b6d54e0c331a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BWZFwbq2Qizs",
        "outputId": "153feddc-e8c2-4b45-ab73-befa3d83700a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_wZfpB4yQlnV",
        "outputId": "cccc221c-467c-47ef-9ecc-cd913f363094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JPRSHItEQovv",
        "outputId": "7c1b5c28-b38d-4309-936f-f0c0d4522b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u8ASQUxgQqlu",
        "outputId": "75fcf3a1-d9c0-4076-ac64-fe9d7e14a955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357244 sha256=f91ab63922107d1fd78a87f2c27fbd3f01ded8b1f9b78b55b949ed1ffc54a3e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b7CLWKRWQtZ3",
        "outputId": "b2457f06-1362-47c7-96b6-be51eab88735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sqlalchemy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LwYA9SgfQtl-",
        "outputId": "ad115ffe-2114-4bf9-ce4f-ffcfad65d31d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (2.0.30)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JGBocmfvQxQB",
        "outputId": "3d4b54ee-bad2-4c79-bd8b-78646a7bb978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.5.5)\n",
            "Collecting qtconsole (from jupyter)\n",
            "  Downloading qtconsole-5.5.2-py3-none-any.whl (123 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/123.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter) (7.7.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter) (3.0.11)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter) (2.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (3.1.4)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (5.10.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (24.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter) (1.3.0)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter) (1.1.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter)\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->jupyter) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter) (4.2.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter) (4.19.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (0.18.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter) (1.2.1)\n",
            "Installing collected packages: qtpy, jedi, qtconsole, jupyter\n",
            "Successfully installed jedi-0.19.1 jupyter-1.0.0 qtconsole-5.5.2 qtpy-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install implicit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6qzs0z0cmVe",
        "outputId": "eb34ebfb-4ca7-4e32-cb1d-ebf13435eb4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting implicit\n",
            "  Downloading implicit-0.7.2-cp310-cp310-manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from implicit) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.10/dist-packages (from implicit) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from implicit) (4.66.4)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from implicit) (3.5.0)\n",
            "Installing collected packages: implicit\n",
            "Successfully installed implicit-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from tensorflow.keras import layers\n",
        "from surprise import Reader, Dataset\n",
        "from surprise import SVD, model_selection\n",
        "from surprise.model_selection import cross_validate\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sqlalchemy import create_engine\n",
        "import sqlite3\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from kerastuner.tuners import RandomSearch"
      ],
      "metadata": {
        "id": "9rXhFf1oRvPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f2a1297-e33c-4336-f63e-5104bf918520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-5ecb58abe349>:21: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzcE0bbCLnZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c60acbf-d3f1-4276-8215-7359e7dc1ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a search query: Marketing\n",
            "Enter a book title to get recommendations: Essentials of Marketing\n",
            "Title: Essentials of Marketing Management\n",
            "Authors: [\"Geoffrey Lancaster\", \"Lester Massingham\"]\n",
            "Publisher: Routledge\n",
            "Published Date: 2010-10\n",
            "Description: The overall success of an organization is dependent on how marketing is able to inform strategy and maintain an operational focus on market needs. This title covers such topics as: consumer and organizational buyer behaviour; product and innovation strategies; direct marketing; and, e-marketing.\n",
            "Page Count: 551\n",
            "Categories: [\"Business & Economics\"]\n",
            "Average Rating: nan\n",
            "Ratings Count: nan\n",
            "Language: en\n",
            "Preview Link: http://books.google.com/books?id=WfctCgAAQBAJ&printsec=frontcover&dq=Marketing&hl=&cd=29&source=gbs_api\n",
            "==================================================\n",
            "Title: Marketing\n",
            "Authors: [\"Juan M. Mart\\u00ednez S\\u00e1nchez\"]\n",
            "Publisher: Firmas Press\n",
            "Published Date: 2010-01-01\n",
            "Description: \n",
            "Page Count: 195\n",
            "Categories: [\"Business & Economics\"]\n",
            "Average Rating: nan\n",
            "Ratings Count: nan\n",
            "Language: es\n",
            "Preview Link: http://books.google.com/books?id=YtPnDwAAQBAJ&printsec=frontcover&dq=Marketing&hl=&cd=32&source=gbs_api\n",
            "==================================================\n",
            "Title: Marketing Analytics\n",
            "Authors: [\"Robert W. Palmatier\", \"J. Andrew Petersen\", \"Frank Germann\"]\n",
            "Publisher: Bloomsbury Publishing\n",
            "Published Date: 2022-03-24\n",
            "Description: Using data analytics and big data in marketing and strategic decision-making is a key priority at many organisations and subsequently a vital part of the skills set for a successful marketing professional operating today. Authored by world-leading authorities in the field, Marketing Analytics provides a thoroughly contemporary overview of marketing analytics and coverage of a wide range of cutting edge data analytics techniques. It offers a powerful framework, organising data analysis techniques around solving four underlying marketing problems: the 'First Principles of Marketing'. In this way, it offers an action-oriented, applied approach to managing marketing complexities and issues, and a sound grounding in making effective decisions based on strong evidence. It is supported by vivid international cases and examples, and applied pedagogical features. The companion website offers comprehensive classroom instruction slides, videos including walk throughs on all the examples and methods in the book, data sets, a test bank and a solution guide for instructors.\n",
            "Page Count: 432\n",
            "Categories: [\"Business & Economics\"]\n",
            "Average Rating: nan\n",
            "Ratings Count: nan\n",
            "Language: en\n",
            "Preview Link: http://books.google.com/books?id=lyxlEAAAQBAJ&printsec=frontcover&dq=Marketing&hl=&cd=8&source=gbs_api\n",
            "==================================================\n",
            "Title: Global Marketing and Advertising\n",
            "Authors: [\"Marieke K. de Mooij\"]\n",
            "Publisher: SAGE\n",
            "Published Date: 2010\n",
            "Description: The Third Edition of the bestseller is packed with cultural, company, and country examples that help explain the paradoxes international marketers are likely to encounter.\n",
            "Page Count: 345\n",
            "Categories: [\"Business & Economics\"]\n",
            "Average Rating: nan\n",
            "Ratings Count: nan\n",
            "Language: en\n",
            "Preview Link: http://books.google.com/books?id=Ph3GMBaboUcC&printsec=frontcover&dq=Marketing&hl=&cd=16&source=gbs_api\n",
            "==================================================\n",
            "Title: Relationship Marketing\n",
            "Authors: [\"Regis Mckenna\"]\n",
            "Publisher: Basic Books\n",
            "Published Date: 1993-05-21\n",
            "Description: From the author of the bestselling The Regis Touch, a simple process for building the crucial relationships that help a company dominate—and own—the market in the Age of the Customer.\n",
            "Page Count: 260\n",
            "Categories: [\"Business & Economics\"]\n",
            "Average Rating: nan\n",
            "Ratings Count: nan\n",
            "Language: en\n",
            "Preview Link: http://books.google.com/books?id=3p8dqNXNehEC&q=Marketing&dq=Marketing&hl=&cd=18&source=gbs_api\n",
            "==================================================\n",
            "Title: Marketing Handbook: Marketing management\n",
            "Authors: [\"Edwin E. Bobrow\", \"Mark David Bobrow\"]\n",
            "Publisher: Irwin Professional Publishing\n",
            "Published Date: 1985\n",
            "Description: \n",
            "Page Count: 528\n",
            "Categories: [\"Economics\"]\n",
            "Average Rating: nan\n",
            "Ratings Count: nan\n",
            "Language: en\n",
            "Preview Link: http://books.google.com/books?id=s5JLAQAAIAAJ&q=Marketing&dq=Marketing&hl=&cd=20&source=gbs_api\n",
            "==================================================\n",
            "Title: The Complete Idiot's Guide to Marketing, 2nd edition\n",
            "Authors: [\"Sarah White\"]\n",
            "Publisher: Penguin\n",
            "Published Date: 2003-11-04\n",
            "Description: From online marketing to old-fashioned word-of-mouth, readers will find a comprehensive update on key marketing basics, as well as such topics as: • Guerilla marketing. • Marketing to Boomers and Latinos. • Online marketing. • Targeted, but affordable direct mail. • Sample marketing plans for several types of small businesses (as well as a couple of larger projects). • Practical, do-it-yourself distribution strategies. • Analysis of business segments and trends, and much more.\n",
            "Page Count: 490\n",
            "Categories: [\"Business & Economics\"]\n",
            "Average Rating: nan\n",
            "Ratings Count: nan\n",
            "Language: en\n",
            "Preview Link: http://books.google.com/books?id=HFPN9hJ9H6UC&printsec=frontcover&dq=Marketing&hl=&cd=23&source=gbs_api\n",
            "==================================================\n",
            "Title: Business-to-business Marketing\n",
            "Authors: [\"Ray Wright\"]\n",
            "Publisher: Pearson Education\n",
            "Published Date: 2004\n",
            "Description: Business-to-business markets are markets where one business markets and sells products and services for an organisation's own use or to sell on to other businesses for their own use. This text provides an overview of business-to-business marketing.\n",
            "Page Count: 540\n",
            "Categories: [\"Business & Economics\"]\n",
            "Average Rating: 3.0\n",
            "Ratings Count: 1.0\n",
            "Language: en\n",
            "Preview Link: http://books.google.com/books?id=JfPVXQOLAWsC&dq=Marketing&hl=&cd=5&source=gbs_api\n",
            "==================================================\n",
            "Title: Business-to-Business Marketing\n",
            "Authors: [\"Ross Brennan\", \"Louise Canning\", \"Raymond McDowell\"]\n",
            "Publisher: SAGE\n",
            "Published Date: 2010-10-20\n",
            "Description: The Second Edition of this bestselling B2B marketing textbook offers the same accessible clarity of insight, combined with updated and engaging examples. Each chapter contains a detailed case study to further engage the reader with the topics examined. - Featuring updated case studies and a range of new examples. - Incorporating additional coverage of B2B branding and the B2B strategic marketing process, and issues of sustainability. - Extended coverage of Key Account Management - Online lecturer support including PowerPoint slides and key web links Drawing on their substantial experience of business-to-business marketing as practitioners, researchers and educators, the authors make this exciting and challenging area accessible to advanced undergraduate and to postgraduate students of marketing, management and business studies. Praise for the Second Edition: 'I found that the first edition of Brennan, Canning and McDowell's text was excellent for raising students' awareness and understanding of the most important concepts and phenomena associated with B2B marketing. The second edition should prove even more successful by using several new case studies and short 'snapshots' to illustrate possible solutions to common B2B marketing dilemmas, such as the design and delivery of business products and services, the selection of promotional tools and alternative routes to market. The new edition also deals clearly with complex issues such as inter-firm relationships and networks, e-B2B, logistics, supply chain management and B2B branding' - Michael Saren, Professor of Marketing, University of Leicester 'This textbook makes a unique contribution to business-to-business teaching: not only does it provide up-to-date cases and issues for discussion that reach to the heart of business-to-business marketing; it also brings in the latest academic debates and makes them both relevant and accessible to the readers. A fantastic addition to any library or course' - Dr Judy Zolkiewski, Senior Lecturer in Business-to-Business Marketing, Manchester Business School 'The advantage of the approach taken by Brennan and his colleagues is that this book manages to convey both the typical North American view of B2B marketing as the optimisation of a set of marketing mix variables, and the more emergent European view of B2B Marketing as being focused on the management of relationships between companies. This updated second edition sees the addition of a number of 'snapshots' in each chapter that bring the subject alive through the description of current examples, as well as some more expansive end-of-chapter case studies. It is truly a most welcome addition to the bookshelves of those students and faculty interested in this facet of marketing' - Peter Naudé, Professor of Marketing, Manchester Business School 'The strength of this text lies in the interconnection of academic theory with real world examples. Special attention has been given to the role that relationships play within the Business-to business environment, linking these to key concepts such as segmentation, targeting and marketing communications, which importantly encompasses the role personal selling as relationshipmmunications building and not just order taking. With good coverage of international cultural differences this is a valuable resource for both students of marketing and sales' - Andrew Whalley, Lecturer in Business-to-Business Marketing, Royal Holloway University of London 'The text provides an authoritative, up-to-date review of organisational strategy development and 'firmographic' market segmentation. It provides a comprehensive literature review and empiric examples through a range of relevant case studies. The approach to strategy formulation, ethics and corporate social responsibility are especially strong' - Stuart Challinor, Lecturer in Marketing, Newcastle University 'This revised second edition offers an excellent contemporary view of Business-to-Business Marketing. Refreshingly, the text is packed with an eclectic mix of largely European case studies that make for extremely interesting reading. It is a 'must read' for any undergraduate or postgraduate Marketing student' - Dr Jonathan Wilson, Senior Lecturer, Ashcroft International Business School, Anglia Ruskin University, Cambridge\n",
            "Page Count: 409\n",
            "Categories: [\"Business & Economics\"]\n",
            "Average Rating: nan\n",
            "Ratings Count: nan\n",
            "Language: en\n",
            "Preview Link: http://books.google.com/books?id=r7hGBncHBYIC&printsec=frontcover&dq=Marketing&hl=&cd=19&source=gbs_api\n",
            "==================================================\n",
            "Title: Readings in Modern Marketing\n",
            "Authors: [\"John A. Quelch\"]\n",
            "Publisher: Chinese University Press\n",
            "Published Date: 2006\n",
            "Description: Readings in Modern Marketing is a collection of Professor Quelch's highly-praised scholarly articles previously published in leading business journals. Topics covered include marketing and business strategy, managing product lines, pricing, managing the point of sales, global marketing, building global brands, marketing and the new technologies, marketing and society, and so forth. Readings in Modern Marketing offers important theories as well as practical, insightful tactics. It is an indispensable source of reference.\n",
            "Page Count: 772\n",
            "Categories: [\"Business & Economics\"]\n",
            "Average Rating: nan\n",
            "Ratings Count: nan\n",
            "Language: en\n",
            "Preview Link: http://books.google.com/books?id=GFw_y_pGwHAC&printsec=frontcover&dq=Marketing&hl=&cd=14&source=gbs_api\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def fetch_books(query, api_key, max_results=40):\n",
        "    url = \"https://www.googleapis.com/books/v1/volumes\"\n",
        "    params = {'q': query, 'key': api_key, 'maxResults': max_results}\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data from Google Books API: {e}\")\n",
        "        return {}\n",
        "\n",
        "def extract_full_book_info(json_data):\n",
        "    books = []\n",
        "    for item in json_data.get('items', []):\n",
        "        volume_info = item.get('volumeInfo', {})\n",
        "        sale_info = item.get('saleInfo', {})\n",
        "        access_info = item.get('accessInfo', {})\n",
        "        book = {\n",
        "            'title': volume_info.get('title'),\n",
        "            'authors': volume_info.get('authors'),\n",
        "            'publisher': volume_info.get('publisher'),\n",
        "            'publishedDate': volume_info.get('publishedDate'),\n",
        "            'description': volume_info.get('description'),\n",
        "            'industryIdentifiers': volume_info.get('industryIdentifiers'),\n",
        "            'pageCount': volume_info.get('pageCount'),\n",
        "            'categories': volume_info.get('categories'),\n",
        "            'averageRating': volume_info.get('averageRating'),\n",
        "            'ratingsCount': volume_info.get('ratingsCount'),\n",
        "            'maturityRating': volume_info.get('maturityRating'),\n",
        "            'imageLinks': volume_info.get('imageLinks'),\n",
        "            'language': volume_info.get('language'),\n",
        "            'previewLink': volume_info.get('previewLink'),\n",
        "            'infoLink': volume_info.get('infoLink'),\n",
        "            'canonicalVolumeLink': volume_info.get('canonicalVolumeLink'),\n",
        "            'saleability': sale_info.get('saleability'),\n",
        "            'isEbook': sale_info.get('isEbook'),\n",
        "            'listPrice': sale_info.get('listPrice'),\n",
        "            'retailPrice': sale_info.get('retailPrice'),\n",
        "            'buyLink': sale_info.get('buyLink'),\n",
        "            'epub': access_info.get('epub', {}).get('isAvailable'),\n",
        "            'pdf': access_info.get('pdf', {}).get('isAvailable'),\n",
        "            'webReaderLink': access_info.get('webReaderLink'),\n",
        "            'accessViewStatus': access_info.get('accessViewStatus'),\n",
        "            'quoteSharingAllowed': access_info.get('quoteSharingAllowed')\n",
        "        }\n",
        "        books.append(book)\n",
        "    return books\n",
        "\n",
        "def create_connection(db_file):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(e)\n",
        "    return conn\n",
        "\n",
        "def create_table(conn):\n",
        "    try:\n",
        "        sql_create_books_table = \"\"\" CREATE TABLE IF NOT EXISTS books (\n",
        "                                        id integer PRIMARY KEY,\n",
        "                                        title text,\n",
        "                                        authors text,\n",
        "                                        publisher text,\n",
        "                                        publishedDate text,\n",
        "                                        description text,\n",
        "                                        industryIdentifiers text,\n",
        "                                        pageCount integer,\n",
        "                                        categories text,\n",
        "                                        averageRating real,\n",
        "                                        ratingsCount integer,\n",
        "                                        maturityRating text,\n",
        "                                        imageLinks text,\n",
        "                                        language text,\n",
        "                                        previewLink text,\n",
        "                                        infoLink text,\n",
        "                                        canonicalVolumeLink text,\n",
        "                                        saleability text,\n",
        "                                        isEbook boolean,\n",
        "                                        listPrice real,\n",
        "                                        retailPrice real,\n",
        "                                        buyLink text,\n",
        "                                        epub boolean,\n",
        "                                        pdf boolean,\n",
        "                                        webReaderLink text,\n",
        "                                        accessViewStatus text,\n",
        "                                        quoteSharingAllowed boolean\n",
        "                                    ); \"\"\"\n",
        "        c = conn.cursor()\n",
        "        c.execute(sql_create_books_table)\n",
        "    except sqlite3.Error as e:\n",
        "        print(e)\n",
        "\n",
        "def recreate_table(conn):\n",
        "    try:\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"DROP TABLE IF EXISTS books\")\n",
        "        create_table(conn)\n",
        "    except sqlite3.Error as e:\n",
        "        print(e)\n",
        "\n",
        "def save_books_to_db(books):\n",
        "    conn = create_connection(\"books.db\")\n",
        "    if conn is not None:\n",
        "        recreate_table(conn)\n",
        "        c = conn.cursor()\n",
        "        for book in books:\n",
        "            c.execute(\"\"\"\n",
        "                INSERT INTO books (title, authors, publisher, publishedDate, description,\n",
        "                industryIdentifiers, pageCount, categories, averageRating, ratingsCount,\n",
        "                maturityRating, imageLinks, language, previewLink, infoLink, canonicalVolumeLink,\n",
        "                saleability, isEbook, listPrice, retailPrice, buyLink, epub, pdf, webReaderLink,\n",
        "                accessViewStatus, quoteSharingAllowed) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "                \"\"\", (\n",
        "                book.get('title'),\n",
        "                json.dumps(book.get('authors')),\n",
        "                book.get('publisher'),\n",
        "                book.get('publishedDate'),\n",
        "                book.get('description'),\n",
        "                json.dumps(book.get('industryIdentifiers')),\n",
        "                book.get('pageCount'),\n",
        "                json.dumps(book.get('categories')),\n",
        "                book.get('averageRating'),\n",
        "                book.get('ratingsCount'),\n",
        "                book.get('maturityRating'),\n",
        "                json.dumps(book.get('imageLinks')),\n",
        "                book.get('language'),\n",
        "                book.get('previewLink'),\n",
        "                book.get('infoLink'),\n",
        "                book.get('canonicalVolumeLink'),\n",
        "                book.get('saleability'),\n",
        "                book.get('isEbook'),\n",
        "                json.dumps(book.get('listPrice')),\n",
        "                json.dumps(book.get('retailPrice')),\n",
        "                book.get('buyLink'),\n",
        "                book.get('epub'),\n",
        "                book.get('pdf'),\n",
        "                book.get('webReaderLink'),\n",
        "                book.get('accessViewStatus'),\n",
        "                book.get('quoteSharingAllowed')\n",
        "            ))\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "def load_books_from_db(database):\n",
        "    conn = create_connection(database)\n",
        "    query = \"SELECT * FROM books\"\n",
        "    df = pd.read_sql_query(query, conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "def recommend_books(book_title, cosine_sim, df):\n",
        "    if book_title not in df['title'].values:\n",
        "        print(f\"Book titled '{book_title}' not found in the database.\")\n",
        "        return pd.DataFrame()\n",
        "    idx = df.index[df['title'] == book_title].tolist()[0]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    book_indices = [i[0] for i in sim_scores]\n",
        "    return df.iloc[book_indices]\n",
        "\n",
        "def display_books(books):\n",
        "    for index, book in books.iterrows():\n",
        "        print(f\"Title: {book['title']}\")\n",
        "        print(f\"Authors: {book.get('authors')}\")\n",
        "        print(f\"Publisher: {book.get('publisher')}\")\n",
        "        print(f\"Published Date: {book.get('publishedDate')}\")\n",
        "        print(f\"Description: {book.get('description')}\")\n",
        "        print(f\"Page Count: {book.get('pageCount')}\")\n",
        "        print(f\"Categories: {book.get('categories')}\")\n",
        "        print(f\"Average Rating: {book.get('averageRating')}\")\n",
        "        print(f\"Ratings Count: {book.get('ratingsCount')}\")\n",
        "        print(f\"Language: {book.get('language')}\")\n",
        "        print(f\"Preview Link: {book.get('previewLink')}\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "def prepare_data(df):\n",
        "    df['description'] = df['description'].fillna('')\n",
        "    df['combined_features'] = (df['title'] + \" \" + df['authors'].fillna('') + \" \" +\n",
        "                               df['categories'].fillna('') + \" \" + df['description'])\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    api_key = 'AIzaSyDdWzNgGVN-QhwCcvCPvdqSalsYiBBZKHo'\n",
        "    query = input(\"Enter a search query: \")\n",
        "    book_data = fetch_books(query, api_key)\n",
        "    books = extract_full_book_info(book_data)\n",
        "    save_books_to_db(books)\n",
        "    database = \"books.db\"\n",
        "    df = load_books_from_db(database)\n",
        "    df = prepare_data(df)\n",
        "    tfidf = TfidfVectorizer(stop_words='english', max_df=0.8, min_df=2, ngram_range=(1, 2))\n",
        "    tfidf_matrix = tfidf.fit_transform(df['combined_features'])\n",
        "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "    book_title = input(\"Enter a book title to get recommendations: \")\n",
        "    recommended_books = recommend_books(book_title, cosine_sim, df)\n",
        "    if not recommended_books.empty:\n",
        "        display_books(recommended_books)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_at_k(recommended_books, relevant_books, k=3):\n",
        "    recommended_k = recommended_books['title'].tolist()[:k]\n",
        "    relevant_count = len(set(recommended_k) & set(relevant_books))\n",
        "    return relevant_count / k\n",
        "\n",
        "def recall_at_k(recommended_books, relevant_books, k=3):\n",
        "    recommended_k = recommended_books['title'].tolist()[:k]\n",
        "    relevant_count = len(set(recommended_k) & set(relevant_books))\n",
        "    return relevant_count / len(relevant_books)\n",
        "\n",
        "def f1_score_at_k(precision, recall):\n",
        "    if precision + recall == 0:\n",
        "        return 0\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "def mean_average_precision_at_k(recommended_books, relevant_books, k=3):\n",
        "    relevant_count = 0\n",
        "    score = 0.0\n",
        "    recommended_k = recommended_books['title'].tolist()[:k]\n",
        "    for i in range(k):\n",
        "        if recommended_k[i] in relevant_books:\n",
        "            relevant_count += 1\n",
        "            score += relevant_count / (i + 1)\n",
        "    return score / min(len(relevant_books), k)\n",
        "\n",
        "def reciprocal_rank_at_k(recommended_books, relevant_books):\n",
        "    recommended_titles = recommended_books['title'].tolist()\n",
        "    for i, book in enumerate(recommended_titles):\n",
        "        if book in relevant_books:\n",
        "            return 1 / (i + 1)\n",
        "    return 0\n",
        "\n",
        "def test_metrics():\n",
        "    database = \"books.db\"\n",
        "    df = load_books_from_db(database)\n",
        "    df = prepare_data(df)\n",
        "    tfidf = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = tfidf.fit_transform(df['description'])\n",
        "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "    test_cases = [\n",
        "        {\n",
        "            \"book_title\": \"Essentials of Marketing\",\n",
        "            \"relevant_books\": [\"Marketing For Dummies\", \"The Marketing Book\", \"Internet Marketing\"]\n",
        "        },\n",
        "    ]\n",
        "    for test in test_cases:\n",
        "        recommended_books = recommend_books(test[\"book_title\"], cosine_sim, df)\n",
        "        if recommended_books.empty:\n",
        "            print(f\"Book titled '{test['book_title']}' not found in the database.\")\n",
        "            continue\n",
        "        precision = precision_at_k(recommended_books, test[\"relevant_books\"], k=3)\n",
        "        recall = recall_at_k(recommended_books, test[\"relevant_books\"], k=3)\n",
        "        f1_score = f1_score_at_k(precision, recall)\n",
        "        map_score = mean_average_precision_at_k(recommended_books, test[\"relevant_books\"], k=3)\n",
        "        rr_score = reciprocal_rank_at_k(recommended_books, test[\"relevant_books\"])\n",
        "        print(f\"Testing book: {test['book_title']}\")\n",
        "        print(f\"Precision@3: {precision}\")\n",
        "        print(f\"Recall@3: {recall}\")\n",
        "        print(f\"F1 Score@3: {f1_score}\")\n",
        "        print(f\"Mean Average Precision@3: {map_score}\")\n",
        "        print(f\"Reciprocal Rank: {rr_score}\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbU4CQaC_hJ9",
        "outputId": "56358f30-efa4-4646-a6bd-4a17f6d59b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing book: Essentials of Marketing\n",
            "Precision@3: 0.6666666666666666\n",
            "Recall@3: 0.6666666666666666\n",
            "F1 Score@3: 0.6666666666666666\n",
            "Mean Average Precision@3: 0.6666666666666666\n",
            "Reciprocal Rank: 1.0\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collaborative Filtering"
      ],
      "metadata": {
        "id": "7e48WcnDxmco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "def fetch_books(query, api_key, max_results=40):\n",
        "    url = \"https://www.googleapis.com/books/v1/volumes\"\n",
        "    params = {'q': query, 'key': api_key, 'maxResults': max_results}\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status()  # Ensure the response is successful\n",
        "        books_data = response.json()\n",
        "        if not books_data.get('items'):\n",
        "            print(\"No books found for the query.\")\n",
        "        return books_data\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data from Google Books API: {e}\")\n",
        "        return {}\n",
        "\n",
        "def create_connection(db_file):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "        print(\"Connection to database successful\")\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"Error connecting to database: {e}\")\n",
        "    return conn\n",
        "\n",
        "def simulate_user_ratings(conn):\n",
        "    books_df = pd.read_sql_query(\"SELECT id, averageRating, ratingsCount FROM books\", conn)\n",
        "    if books_df.empty:\n",
        "        print(\"No books in the database to rate.\")\n",
        "        return pd.DataFrame()  # Return empty DataFrame if no books available\n",
        "\n",
        "    user_ids = range(1, 6)  # Simulate 5 users\n",
        "    ratings = []\n",
        "    for _, row in books_df.iterrows():\n",
        "        book_id = row['id']\n",
        "        avg_rating = row['averageRating'] if not pd.isna(row['averageRating']) else 3\n",
        "        ratings_count = row['ratingsCount'] if not pd.isna(row['ratingsCount']) else 1\n",
        "        ratings_per_user = max(1, ratings_count // len(user_ids))\n",
        "        for user_id in user_ids:\n",
        "            if np.random.rand() > 0.2:  # Leave some books unrated by each user\n",
        "                for _ in range(ratings_per_user):\n",
        "                    rating = np.random.normal(loc=avg_rating, scale=1.0)\n",
        "                    rating = min(max(round(rating), 1), 5)  # Ensure the rating is between 1 and 5\n",
        "                    ratings.append((user_id, book_id, rating))\n",
        "    ratings_df = pd.DataFrame(ratings, columns=['user_id', 'book_id', 'rating'])\n",
        "    if ratings_df.empty:\n",
        "        print(\"No ratings generated.\")\n",
        "    return ratings_df\n",
        "\n",
        "def get_collaborative_recommendations(user_id, svd_model, books_df, ratings_df, num_recommendations=5):\n",
        "    book_ids = books_df['id'].unique()\n",
        "    print(f\"Total books: {len(book_ids)}\")  # Check total books available\n",
        "\n",
        "    book_titles = books_df.set_index('id')['title'].to_dict()\n",
        "    predictions = []\n",
        "    for book_id in book_ids:\n",
        "        if ratings_df[(ratings_df['user_id'] == user_id) & (ratings_df['book_id'] == book_id)].empty:\n",
        "            predicted_rating = svd_model.predict(user_id, book_id).est\n",
        "            predictions.append((book_id, predicted_rating))\n",
        "        else:\n",
        "            print(f\"Book {book_id} already rated by user {user_id}\")\n",
        "\n",
        "    print(f\"Total predictions made: {len(predictions)}\")  # Check how many predictions were made\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "    recommended_books = [book_titles.get(book_id, \"Unknown Book Title\") for book_id, _ in predictions[:num_recommendations]]\n",
        "    return recommended_books\n",
        "\n",
        "def extract_full_book_info(book_data):\n",
        "    # Placeholder function to extract book info\n",
        "    books = []\n",
        "    for item in book_data.get('items', []):\n",
        "        book = {\n",
        "            'id': item['id'],\n",
        "            'title': item['volumeInfo'].get('title', 'N/A'),\n",
        "            'averageRating': item['volumeInfo'].get('averageRating', None),\n",
        "            'ratingsCount': item['volumeInfo'].get('ratingsCount', None)\n",
        "        }\n",
        "        books.append(book)\n",
        "    return books\n",
        "\n",
        "def save_books_to_db(books):\n",
        "    # Placeholder function to save books to the database\n",
        "    conn = create_connection('books.db')\n",
        "    if conn is not None:\n",
        "        df = pd.DataFrame(books)\n",
        "        df.to_sql('books', conn, if_exists='replace', index=False)\n",
        "        print(\"Books saved to database.\")\n",
        "    else:\n",
        "        print(\"Failed to connect to the database.\")\n",
        "\n",
        "def collaborative_filtering(ratings_df):\n",
        "    reader = Reader(rating_scale=(1, 5))\n",
        "    data = Dataset.load_from_df(ratings_df, reader)\n",
        "    trainset, testset = train_test_split(data, test_size=0.2)\n",
        "    svd = SVD()\n",
        "    svd.fit(trainset)\n",
        "    return svd\n",
        "\n",
        "def main():\n",
        "    api_key = 'AIzaSyDdWzNgGVN-QhwCcvCPvdqSalsYiBBZKHo'  # Replace with your actual API key\n",
        "    query = \"Marketing Campaign Development\"\n",
        "    book_data = fetch_books(query, api_key)\n",
        "    books = extract_full_book_info(book_data)\n",
        "    save_books_to_db(books)\n",
        "\n",
        "    conn = create_connection('books.db')\n",
        "    ratings_df = simulate_user_ratings(conn)\n",
        "    svd_model = collaborative_filtering(ratings_df)\n",
        "\n",
        "    books_df = pd.read_sql_query(\"SELECT * FROM books\", conn)\n",
        "    user_id = 1\n",
        "    recommendations = get_collaborative_recommendations(user_id, svd_model, books_df, ratings_df)\n",
        "    print(f\"Recommendations for user {user_id}: {recommendations}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6_xzV5Rxl7b",
        "outputId": "a49d76fe-8701-4ab2-9ff8-35296eab5eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection to database successful\n",
            "Books saved to database.\n",
            "Connection to database successful\n",
            "Total books: 40\n",
            "Book gGgcSSr4d1IC already rated by user 1\n",
            "Book l5OMJ6T53IQC already rated by user 1\n",
            "Book yrU6EAAAQBAJ already rated by user 1\n",
            "Book bIN7AwAAQBAJ already rated by user 1\n",
            "Book t2y8EAAAQBAJ already rated by user 1\n",
            "Book XDoYcqmFAx8C already rated by user 1\n",
            "Book XoMt2xlBQAAC already rated by user 1\n",
            "Book joEkP6e_MVsC already rated by user 1\n",
            "Book xAvPKgd-jMsC already rated by user 1\n",
            "Book GmmdEAAAQBAJ already rated by user 1\n",
            "Book a7IaDAAAQBAJ already rated by user 1\n",
            "Book aqo_EAAAQBAJ already rated by user 1\n",
            "Book UOT4DwAAQBAJ already rated by user 1\n",
            "Book vAe_yQEACAAJ already rated by user 1\n",
            "Book lCZjCz58_L0C already rated by user 1\n",
            "Book yCkB3ruNe_0C already rated by user 1\n",
            "Book A4hO-zwxXi8C already rated by user 1\n",
            "Book -aB1AwAAQBAJ already rated by user 1\n",
            "Book J_cIEAAAQBAJ already rated by user 1\n",
            "Book yMjTDQAAQBAJ already rated by user 1\n",
            "Book _TDaEAAAQBAJ already rated by user 1\n",
            "Book JL59DwAAQBAJ already rated by user 1\n",
            "Book iOC2AAAAIAAJ already rated by user 1\n",
            "Book Br3pVH-syUUC already rated by user 1\n",
            "Book WZITmBTCOskC already rated by user 1\n",
            "Total predictions made: 15\n",
            "Recommendations for user 1: ['Strategic Marketing Planning for the Small to Medium-sized Business', 'Small Business Marketing Strategies All-in-One For Dummies', '10 Ways To Screw Up An Ad Campaign', 'Hands-On Social Marketing', 'Be Seen, Be Heard, Be Memorable']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.accuracy import mae, rmse\n",
        "from collections import defaultdict\n",
        "\n",
        "def fetch_books(query, api_key, max_results=40):\n",
        "    url = \"https://www.googleapis.com/books/v1/volumes\"\n",
        "    params = {'q': query, 'key': api_key, 'maxResults': max_results}\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status()  # Ensure the response is successful\n",
        "        books_data = response.json()\n",
        "        if not books_data.get('items'):\n",
        "            print(\"No books found for the query.\")\n",
        "        return books_data\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data from Google Books API: {e}\")\n",
        "        return {}\n",
        "\n",
        "def create_connection(db_file):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "        print(\"Connection to database successful\")\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"Error connecting to database: {e}\")\n",
        "    return conn\n",
        "\n",
        "def simulate_user_ratings(conn):\n",
        "    books_df = pd.read_sql_query(\"SELECT id, averageRating, ratingsCount FROM books\", conn)\n",
        "    if books_df.empty:\n",
        "        print(\"No books in the database to rate.\")\n",
        "        return pd.DataFrame()  # Return empty DataFrame if no books available\n",
        "\n",
        "    user_ids = range(1, 6)  # Simulate 5 users\n",
        "    ratings = []\n",
        "    for _, row in books_df.iterrows():\n",
        "        book_id = row['id']\n",
        "        avg_rating = row['averageRating'] if not pd.isna(row['averageRating']) else 3\n",
        "        ratings_count = row['ratingsCount'] if not pd.isna(row['ratingsCount']) else 1\n",
        "        ratings_per_user = max(1, ratings_count // len(user_ids))\n",
        "        for user_id in user_ids:\n",
        "            if np.random.rand() > 0.2:  # Leave some books unrated by each user\n",
        "                for _ in range(ratings_per_user):\n",
        "                    rating = np.random.normal(loc=avg_rating, scale=1.0)\n",
        "                    rating = min(max(round(rating), 1), 5)  # Ensure the rating is between 1 and 5\n",
        "                    ratings.append((user_id, book_id, rating))\n",
        "    ratings_df = pd.DataFrame(ratings, columns=['user_id', 'book_id', 'rating'])\n",
        "    if ratings_df.empty:\n",
        "        print(\"No ratings generated.\")\n",
        "    return ratings_df\n",
        "\n",
        "def get_collaborative_recommendations(user_id, svd_model, books_df, ratings_df, num_recommendations=5):\n",
        "    book_ids = books_df['id'].unique()\n",
        "    print(f\"Total books: {len(book_ids)}\")  # Check total books available\n",
        "\n",
        "    book_titles = books_df.set_index('id')['title'].to_dict()\n",
        "    predictions = []\n",
        "    for book_id in book_ids:\n",
        "        if ratings_df[(ratings_df['user_id'] == user_id) & (ratings_df['book_id'] == book_id)].empty:\n",
        "            predicted_rating = svd_model.predict(user_id, book_id).est\n",
        "            predictions.append((book_id, predicted_rating))\n",
        "        else:\n",
        "            print(f\"Book {book_id} already rated by user {user_id}\")\n",
        "\n",
        "    print(f\"Total predictions made: {len(predictions)}\")  # Check how many predictions were made\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "    recommended_books = [book_titles.get(book_id, \"Unknown Book Title\") for book_id, _ in predictions[:num_recommendations]]\n",
        "    return recommended_books\n",
        "\n",
        "def extract_full_book_info(book_data):\n",
        "    books = []\n",
        "    for item in book_data.get('items', []):\n",
        "        book = {\n",
        "            'id': item['id'],\n",
        "            'title': item['volumeInfo'].get('title', 'N/A'),\n",
        "            'averageRating': item['volumeInfo'].get('averageRating', None),\n",
        "            'ratingsCount': item['volumeInfo'].get('ratingsCount', None)\n",
        "        }\n",
        "        books.append(book)\n",
        "    return books\n",
        "\n",
        "def save_books_to_db(books):\n",
        "    conn = create_connection('books.db')\n",
        "    if conn is not None:\n",
        "        df = pd.DataFrame(books)\n",
        "        df.to_sql('books', conn, if_exists='replace', index=False)\n",
        "        print(\"Books saved to database.\")\n",
        "    else:\n",
        "        print(\"Failed to connect to the database.\")\n",
        "\n",
        "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
        "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
        "    # First map the predictions to each user.\n",
        "    user_est_true = defaultdict(list)\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        # Sort user ratings by estimated value\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        # Number of relevant items\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # Number of recommended items in top k\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "\n",
        "        # Number of relevant and recommended items in top k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "\n",
        "        # Precision@K: Proportion of recommended items that are relevant\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
        "\n",
        "        # Recall@K: Proportion of relevant items that are recommended\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
        "\n",
        "    return precisions, recalls\n",
        "\n",
        "def collaborative_filtering(ratings_df):\n",
        "    reader = Reader(rating_scale=(1, 5))\n",
        "    data = Dataset.load_from_df(ratings_df, reader)\n",
        "    trainset, testset = train_test_split(data, test_size=0.2)\n",
        "    svd = SVD()\n",
        "    svd.fit(trainset)\n",
        "\n",
        "    # Calculate MAE and RMSE\n",
        "    test_predictions = svd.test(testset)\n",
        "    print(\"MAE:\", mae(test_predictions))\n",
        "    print(\"RMSE:\", rmse(test_predictions))\n",
        "\n",
        "    # Calculate Precision@k and Recall@k\n",
        "    k = 5\n",
        "    precisions, recalls = precision_recall_at_k(test_predictions, k=k)\n",
        "    print(f\"Precision@{k}: {sum(precisions.values()) / len(precisions)}\")\n",
        "    print(f\"Recall@{k}: {sum(recalls.values()) / len(recalls)}\")\n",
        "\n",
        "    return svd, test_predictions\n",
        "\n",
        "def main():\n",
        "    api_key = 'AIzaSyDdWzNgGVN-QhwCcvCPvdqSalsYiBBZKHo'  # Replace with your actual API key\n",
        "    query = \"Marketing Campaign Development\"\n",
        "    book_data = fetch_books(query, api_key)\n",
        "    books = extract_full_book_info(book_data)\n",
        "    save_books_to_db(books)\n",
        "\n",
        "    conn = create_connection('books.db')\n",
        "    ratings_df = simulate_user_ratings(conn)\n",
        "    svd_model, test_predictions = collaborative_filtering(ratings_df)\n",
        "\n",
        "    books_df = pd.read_sql_query(\"SELECT * FROM books\", conn)\n",
        "    user_id = 1\n",
        "    recommendations = get_collaborative_recommendations(user_id, svd_model, books_df, ratings_df)\n",
        "    print(f\"Recommendations for user {user_id}: {recommendations}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FklYOlhdagpF",
        "outputId": "10d73ff4-b843-4756-ab64-cfeb43375273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection to database successful\n",
            "Books saved to database.\n",
            "Connection to database successful\n",
            "MAE:  0.8789\n",
            "MAE: 0.8788888152986465\n",
            "RMSE: 1.0781\n",
            "RMSE: 1.0781146315119785\n",
            "Precision@5: 0.7\n",
            "Recall@5: 0.6416666666666666\n",
            "Total books: 40\n",
            "Book xFlXcScu-V8C already rated by user 1\n",
            "Book JOTtAAAAMAAJ already rated by user 1\n",
            "Book gGgcSSr4d1IC already rated by user 1\n",
            "Book iZUeo2IM01kC already rated by user 1\n",
            "Book l5OMJ6T53IQC already rated by user 1\n",
            "Book yrU6EAAAQBAJ already rated by user 1\n",
            "Book bIN7AwAAQBAJ already rated by user 1\n",
            "Book mAuptAEACAAJ already rated by user 1\n",
            "Book t2y8EAAAQBAJ already rated by user 1\n",
            "Book VEoa0AEACAAJ already rated by user 1\n",
            "Book XDoYcqmFAx8C already rated by user 1\n",
            "Book XoMt2xlBQAAC already rated by user 1\n",
            "Book joEkP6e_MVsC already rated by user 1\n",
            "Book xAvPKgd-jMsC already rated by user 1\n",
            "Book GmmdEAAAQBAJ already rated by user 1\n",
            "Book mc5CR1di40cC already rated by user 1\n",
            "Book a7IaDAAAQBAJ already rated by user 1\n",
            "Book yfZyAwAAQBAJ already rated by user 1\n",
            "Book aqo_EAAAQBAJ already rated by user 1\n",
            "Book UOT4DwAAQBAJ already rated by user 1\n",
            "Book WB1OZRVeFBUC already rated by user 1\n",
            "Book lCZjCz58_L0C already rated by user 1\n",
            "Book A4hO-zwxXi8C already rated by user 1\n",
            "Book J_cIEAAAQBAJ already rated by user 1\n",
            "Book yMjTDQAAQBAJ already rated by user 1\n",
            "Book _TDaEAAAQBAJ already rated by user 1\n",
            "Book JL59DwAAQBAJ already rated by user 1\n",
            "Book vRm0CAAAQBAJ already rated by user 1\n",
            "Book BS3lrQEACAAJ already rated by user 1\n",
            "Book iOC2AAAAIAAJ already rated by user 1\n",
            "Book Br3pVH-syUUC already rated by user 1\n",
            "Book g8iiKZulTtEC already rated by user 1\n",
            "Book SykxjgEACAAJ already rated by user 1\n",
            "Total predictions made: 7\n",
            "Recommendations for user 1: ['Small Business Marketing Strategies All-in-One For Dummies', 'Think Before You Engage', '10 Ways To Screw Up An Ad Campaign', 'Strategic Marketing Planning for the Small to Medium-sized Business', 'Social Media Marketing for Beginners']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbors (KNN)\n"
      ],
      "metadata": {
        "id": "MPcJcZ3ecKi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import KNNBasic\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "def knn_recommender(ratings_df):\n",
        "    reader = Reader(rating_scale=(1, 5))\n",
        "    data = Dataset.load_from_df(ratings_df[['user_id', 'book_id', 'rating']], reader)\n",
        "    trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "    # KNNBasic menggunakan kesamaan kosinus\n",
        "    algo = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})\n",
        "    algo.fit(trainset)\n",
        "\n",
        "    predictions = algo.test(testset)\n",
        "    accuracy.rmse(predictions)\n",
        "    accuracy.mae(predictions)\n",
        "\n",
        "    return algo\n",
        "\n",
        "def main_knn():\n",
        "    api_key = 'AIzaSyDdWzNgGVN-QhwCcvCPvdqSalsYiBBZKHo'  # Replace with your actual API key\n",
        "    query = \"Marketing Campaign Development\"\n",
        "    book_data = fetch_books(query, api_key)\n",
        "    books = extract_full_book_info(book_data)\n",
        "    save_books_to_db(books)\n",
        "\n",
        "    conn = create_connection('books.db')\n",
        "    ratings_df = simulate_user_ratings(conn)\n",
        "    knn_model = knn_recommender(ratings_df)\n",
        "\n",
        "    books_df = pd.read_sql_query(\"SELECT * FROM books\", conn)\n",
        "    user_id = 1\n",
        "    recommendations = get_collaborative_recommendations(user_id, knn_model, books_df, ratings_df)\n",
        "    print(f\"Recommendations for user {user_id}: {recommendations}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_knn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rqKAV2NcKC_",
        "outputId": "863fd2d5-226b-4e95-88d9-e9f795456dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection to database successful\n",
            "Books saved to database.\n",
            "Connection to database successful\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.4571\n",
            "MAE:  1.2490\n",
            "Total books: 40\n",
            "Book xFlXcScu-V8C already rated by user 1\n",
            "Book JOTtAAAAMAAJ already rated by user 1\n",
            "Book gGgcSSr4d1IC already rated by user 1\n",
            "Book ycRWDwAAQBAJ already rated by user 1\n",
            "Book iZUeo2IM01kC already rated by user 1\n",
            "Book l5OMJ6T53IQC already rated by user 1\n",
            "Book yrU6EAAAQBAJ already rated by user 1\n",
            "Book bIN7AwAAQBAJ already rated by user 1\n",
            "Book RhMvDAAAQBAJ already rated by user 1\n",
            "Book t2y8EAAAQBAJ already rated by user 1\n",
            "Book VEoa0AEACAAJ already rated by user 1\n",
            "Book XDoYcqmFAx8C already rated by user 1\n",
            "Book XoMt2xlBQAAC already rated by user 1\n",
            "Book joEkP6e_MVsC already rated by user 1\n",
            "Book xAvPKgd-jMsC already rated by user 1\n",
            "Book mc5CR1di40cC already rated by user 1\n",
            "Book a7IaDAAAQBAJ already rated by user 1\n",
            "Book aqo_EAAAQBAJ already rated by user 1\n",
            "Book WB1OZRVeFBUC already rated by user 1\n",
            "Book vAe_yQEACAAJ already rated by user 1\n",
            "Book A4hO-zwxXi8C already rated by user 1\n",
            "Book -aB1AwAAQBAJ already rated by user 1\n",
            "Book J_cIEAAAQBAJ already rated by user 1\n",
            "Book yMjTDQAAQBAJ already rated by user 1\n",
            "Book _TDaEAAAQBAJ already rated by user 1\n",
            "Book JL59DwAAQBAJ already rated by user 1\n",
            "Book vRm0CAAAQBAJ already rated by user 1\n",
            "Book 96ChAQAACAAJ already rated by user 1\n",
            "Book Br3pVH-syUUC already rated by user 1\n",
            "Book g8iiKZulTtEC already rated by user 1\n",
            "Book SykxjgEACAAJ already rated by user 1\n",
            "Total predictions made: 9\n",
            "Recommendations for user 1: ['Digital Marketing Excellence', 'Think Before You Engage', 'Social Media Marketing Made Simple', 'Marketing Strategy', 'Optimal Database Marketing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix Factorization using Alternating Least Squares (ALS)"
      ],
      "metadata": {
        "id": "V7qAXZLFgatl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import implicit\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "def als_recommender(ratings_df):\n",
        "    # Create mappings for user_id and book_id to integer indices\n",
        "    user_ids = ratings_df['user_id'].astype(str).unique()\n",
        "    book_ids = ratings_df['book_id'].astype(str).unique()\n",
        "\n",
        "    user_id_map = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
        "    book_id_map = {book_id: idx for idx, book_id in enumerate(book_ids)}\n",
        "\n",
        "    # Map original IDs to new numeric IDs\n",
        "    ratings_df['user_id'] = ratings_df['user_id'].astype(str).map(user_id_map)\n",
        "    ratings_df['book_id'] = ratings_df['book_id'].astype(str).map(book_id_map)\n",
        "\n",
        "    # Convert data frame to sparse matrix\n",
        "    user_item_matrix = csr_matrix((ratings_df['rating'], (ratings_df['user_id'], ratings_df['book_id'])))\n",
        "\n",
        "    model = implicit.als.AlternatingLeastSquares(factors=20, regularization=0.1, iterations=50)\n",
        "    model.fit(user_item_matrix)\n",
        "\n",
        "    return model, user_item_matrix, user_id_map, book_id_map\n",
        "\n",
        "def get_als_recommendations(user_id, model, user_item_matrix, user_id_map, book_id_map, books_df, num_recommendations=5):\n",
        "    # Map user_id to internal ID\n",
        "    if str(user_id) not in user_id_map:\n",
        "        raise KeyError(f\"User ID {user_id} not found in user_id_map.\")\n",
        "    internal_user_id = user_id_map[str(user_id)]\n",
        "    user_ratings = user_item_matrix[internal_user_id]\n",
        "    recommended_indices, scores = model.recommend(internal_user_id, user_ratings, N=num_recommendations)\n",
        "\n",
        "    book_titles = books_df.set_index('id')['title'].to_dict()\n",
        "    reverse_book_id_map = {v: k for k, v in book_id_map.items()}\n",
        "\n",
        "    recommended_books = [book_titles.get(reverse_book_id_map[idx], \"Unknown Book Title\") for idx in recommended_indices]\n",
        "    return recommended_books\n",
        "\n",
        "\n",
        "def main_als():\n",
        "    api_key = 'AIzaSyDdWzNgGVN-QhwCcvCPvdqSalsYiBBZKHo'  # Replace with your actual API key\n",
        "    query = \"Marketing Campaign Development\"\n",
        "    book_data = fetch_books(query, api_key)\n",
        "    books = extract_full_book_info(book_data)\n",
        "    save_books_to_db(books)\n",
        "\n",
        "    conn = create_connection('books.db')\n",
        "    ratings_df = simulate_user_ratings(conn)\n",
        "\n",
        "    # Debug: Print the initial ratings_df to check its content\n",
        "    print(\"Initial ratings_df:\")\n",
        "    print(ratings_df.head())\n",
        "\n",
        "    als_model, user_item_matrix, user_id_map, book_id_map = als_recommender(ratings_df)\n",
        "\n",
        "    # Debug: Print user_id_map to check its content\n",
        "    print(\"User ID Map:\")\n",
        "    print(user_id_map)\n",
        "\n",
        "    books_df = pd.read_sql_query(\"SELECT * FROM books\", conn)\n",
        "    user_id = 2  # Adjust this to match an existing user in your ratings_df\n",
        "    recommendations = get_als_recommendations(user_id, als_model, user_item_matrix, user_id_map, book_id_map, books_df)\n",
        "    print(f\"Recommendations for user {user_id}: {recommendations}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_als()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306,
          "referenced_widgets": [
            "27936c3d77ca435bbbdc8a1f8467996c",
            "9db96d69fb2f4159b257bb2b20f517df",
            "ce040ed3088e477c8cea9db03a26066f",
            "973df260183142d2ae0d338342756d99",
            "ee26f7004709436db16799c082eea0dd",
            "ac92366fa41440bda19ce182562b32f3",
            "4394e94f4de44c5582169277582b7cf8",
            "96fdc78170ae46ba8ad0dbd2848304ba",
            "df57b1aa7ff2498a97f73b1c478d1326",
            "04462b275dfc40e4ad9e953eddfa8c03",
            "cea1c45cbf29457f9acf8af5d3eeddc9"
          ]
        },
        "id": "1E5Rk6X2cacY",
        "outputId": "c1358b1c-afd0-4ffb-adf4-ad1285273b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection to database successful\n",
            "Books saved to database.\n",
            "Connection to database successful\n",
            "Initial ratings_df:\n",
            "   user_id       book_id  rating\n",
            "0        1  xFlXcScu-V8C       3\n",
            "1        2  xFlXcScu-V8C       5\n",
            "2        3  xFlXcScu-V8C       2\n",
            "3        4  xFlXcScu-V8C       2\n",
            "4        5  xFlXcScu-V8C       4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27936c3d77ca435bbbdc8a1f8467996c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User ID Map:\n",
            "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4}\n",
            "Recommendations for user 2: ['Successful Marketing Strategies for Nonprofit Organizations', 'Think Before You Engage', 'Strategic Marketing Planning for the Small to Medium Sized Business', 'Hands-On Social Marketing', 'Digital Domination: How to Build a High-Performing Marketing Organization in the Digital Age']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow Lite"
      ],
      "metadata": {
        "id": "7siJrAnZLZKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "# Function to fetch books from Google Books API\n",
        "def fetch_books(query, api_key, max_results=40):\n",
        "    url = \"https://www.googleapis.com/books/v1/volumes\"\n",
        "    params = {'q': query, 'key': api_key, 'maxResults': max_results}\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data from Google Books API: {e}\")\n",
        "        return {}\n",
        "\n",
        "# Function to extract book information from the API response\n",
        "def extract_full_book_info(json_data):\n",
        "    books = []\n",
        "    for item in json_data.get('items', []):\n",
        "        volume_info = item.get('volumeInfo', {})\n",
        "        book = {\n",
        "            'id': item.get('id'),\n",
        "            'title': volume_info.get('title'),\n",
        "            'authors': volume_info.get('authors'),\n",
        "            'averageRating': volume_info.get('averageRating'),\n",
        "            'ratingsCount': volume_info.get('ratingsCount'),\n",
        "        }\n",
        "        books.append(book)\n",
        "    return books\n",
        "\n",
        "# Function to create a SQLite database connection\n",
        "def create_connection(db_file):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(e)\n",
        "    return conn\n",
        "\n",
        "# Function to create the books table\n",
        "def create_table(conn):\n",
        "    try:\n",
        "        sql_create_books_table = \"\"\" CREATE TABLE IF NOT EXISTS books (\n",
        "                                        id text PRIMARY KEY,\n",
        "                                        title text,\n",
        "                                        authors text,\n",
        "                                        averageRating real,\n",
        "                                        ratingsCount integer\n",
        "                                    ); \"\"\"\n",
        "        c = conn.cursor()\n",
        "        c.execute(sql_create_books_table)\n",
        "    except sqlite3.Error as e:\n",
        "        print(e)\n",
        "\n",
        "# Function to recreate the books table\n",
        "def recreate_table(conn):\n",
        "    try:\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"DROP TABLE IF EXISTS books\")\n",
        "        create_table(conn)\n",
        "    except sqlite3.Error as e:\n",
        "        print(e)\n",
        "\n",
        "# Function to save books to the database\n",
        "def save_books_to_db(books):\n",
        "    conn = create_connection(\"books.db\")\n",
        "    if conn is not None:\n",
        "        recreate_table(conn)\n",
        "        c = conn.cursor()\n",
        "        for book in books:\n",
        "            c.execute(\"\"\"\n",
        "                INSERT OR REPLACE INTO books (id, title, authors, averageRating, ratingsCount)\n",
        "                VALUES (?, ?, ?, ?, ?)\n",
        "                \"\"\", (\n",
        "                book.get('id'),\n",
        "                book.get('title'),\n",
        "                json.dumps(book.get('authors')),\n",
        "                book.get('averageRating'),\n",
        "                book.get('ratingsCount')\n",
        "            ))\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "# Function to load books from the database\n",
        "def load_books_from_db():\n",
        "    conn = create_connection(\"books.db\")\n",
        "    query = \"SELECT * FROM books\"\n",
        "    df = pd.read_sql_query(query, conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "# Define the TensorFlow model for book recommendations\n",
        "def build_model(hp):\n",
        "    user_input = tf.keras.layers.Input(shape=(1,), name='user')\n",
        "    book_input = tf.keras.layers.Input(shape=(1,), name='book')\n",
        "\n",
        "    user_embedding = tf.keras.layers.Embedding(hp.Int('num_users', min_value=500, max_value=1500, step=100), hp.Int('embedding_output_dim', min_value=20, max_value=100, step=10))(user_input)\n",
        "    book_embedding = tf.keras.layers.Embedding(hp.Int('num_books', min_value=500, max_value=1500, step=100), hp.Int('embedding_output_dim', min_value=20, max_value=100, step=10))(book_input)\n",
        "\n",
        "    user_vec = tf.keras.layers.Flatten()(user_embedding)\n",
        "    book_vec = tf.keras.layers.Flatten()(book_embedding)\n",
        "\n",
        "    x = tf.keras.layers.Concatenate()([user_vec, book_vec])\n",
        "    x = tf.keras.layers.Dense(hp.Int('units', min_value=32, max_value=512, step=32), activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1))(x)\n",
        "    output = tf.keras.layers.Dense(1, activation='linear')(x)\n",
        "\n",
        "    model = tf.keras.models.Model([user_input, book_input], output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='mean_squared_error',\n",
        "                  metrics=['mse'])\n",
        "    return model\n",
        "\n",
        "# Function to prepare data for training\n",
        "def prepare_data(df):\n",
        "    user_ids = np.random.randint(1, 1000, df.shape[0])\n",
        "    book_ids = np.array(range(1, df.shape[0] + 1))\n",
        "    ratings = df['averageRating'].fillna(3).values\n",
        "    return user_ids, book_ids, ratings\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    api_key = 'AIzaSyDdWzNgGVN-QhwCcvCPvdqSalsYiBBZKHo'  # Replace with your actual API key\n",
        "    query = \"Marketing\"\n",
        "    book_data = fetch_books(query, api_key)\n",
        "    books = extract_full_book_info(book_data)\n",
        "    save_books_to_db(books)\n",
        "\n",
        "    df = load_books_from_db()\n",
        "    user_ids, book_ids, ratings = prepare_data(df)\n",
        "\n",
        "    num_users = 1000  # Simulated number of users\n",
        "    num_books = len(df) + 1  # Number of books\n",
        "\n",
        "    # Prepare the training data\n",
        "    user_ids, book_ids, ratings = prepare_data(df)\n",
        "    user_ids = np.array(user_ids)\n",
        "    book_ids = np.array(book_ids)\n",
        "    ratings = np.array(ratings)\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    train_user_ids, val_user_ids, train_book_ids, val_book_ids, train_ratings, val_ratings = train_test_split(\n",
        "        user_ids, book_ids, ratings, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Instantiate and compile the TensorFlow model\n",
        "    tuner = RandomSearch(\n",
        "        build_model,\n",
        "        objective='val_mse',\n",
        "        max_trials=5,\n",
        "        executions_per_trial=3,\n",
        "        directory='hyperparam_tuning',\n",
        "        project_name='book_recommender'\n",
        "    )\n",
        "\n",
        "    # Use numpy arrays for training and validation data\n",
        "    train_data = [train_user_ids, train_book_ids]\n",
        "    val_data = [val_user_ids, val_book_ids]\n",
        "\n",
        "    tuner.search([np.array(train_data[0]), np.array(train_data[1])], np.array(train_ratings), epochs=10, validation_data=([np.array(val_data[0]), np.array(val_data[1])], np.array(val_ratings)))\n",
        "\n",
        "    # Get the optimal hyperparameters\n",
        "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "    # Build the model with the optimal hyperparameters and train it\n",
        "    model = build_model(best_hps)\n",
        "    history = model.fit([np.array(train_user_ids), np.array(train_book_ids)], np.array(train_ratings), epochs=10, validation_data=([np.array(val_user_ids), np.array(val_book_ids)], np.array(val_ratings)))\n",
        "\n",
        "    # Save the trained model\n",
        "    model.save(\"recommender_model\")\n",
        "\n",
        "    # Convert the saved model to TensorFlow Lite\n",
        "    converter = tf.lite.TFLiteConverter.from_saved_model(\"recommender_model\")\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Save the TensorFlow Lite model to a file\n",
        "    with open(\"recommender_model.tflite\", \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    print(\"Model converted to tflite format and saved as recommender_model.tflite\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2PeKpq1CRYm",
        "outputId": "da1eb462-ba0a-4918-ae85-43be659695c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 01s]\n",
            "\n",
            "Best val_mse So Far: 8.87738291422526\n",
            "Total elapsed time: 00h 00m 14s\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 10.2427 - mse: 10.2427 - val_loss: 9.8022 - val_mse: 9.8022\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 10.0587 - mse: 10.0587 - val_loss: 9.6962 - val_mse: 9.6962\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 9.8713 - mse: 9.8713 - val_loss: 9.5910 - val_mse: 9.5910\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 9.6993 - mse: 9.6993 - val_loss: 9.4866 - val_mse: 9.4866\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.5091 - mse: 9.5091 - val_loss: 9.3831 - val_mse: 9.3831\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 9.3151 - mse: 9.3151 - val_loss: 9.2800 - val_mse: 9.2800\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.1341 - mse: 9.1341 - val_loss: 9.1776 - val_mse: 9.1776\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.9433 - mse: 8.9433 - val_loss: 9.0749 - val_mse: 9.0749\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.7355 - mse: 8.7355 - val_loss: 8.9720 - val_mse: 8.9720\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.5018 - mse: 8.5018 - val_loss: 8.8692 - val_mse: 8.8692\n",
            "Model converted to tflite format and saved as recommender_model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"recommender_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Test the model with a sample input.\n",
        "def predict(user_id, book_id):\n",
        "    input_data = {\n",
        "        'user': np.array([[user_id]], dtype=np.float32),  # Convert to FLOAT32\n",
        "        'book': np.array([[book_id]], dtype=np.float32)  # Convert to FLOAT32\n",
        "    }\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data['user'])\n",
        "    interpreter.set_tensor(input_details[1]['index'], input_data['book'])\n",
        "\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    return output_data[0][0]\n",
        "\n",
        "# Example predictions\n",
        "print(f\"Predicted rating for user 1 and book 1: {predict(1, 1)}\")\n",
        "print(f\"Predicted rating for user 2 and book 2: {predict(2, 2)}\")\n",
        "\n",
        "# Function to evaluate the model using mean squared error and mean absolute error\n",
        "def evaluate_model(user_ids, book_ids, actual_ratings):\n",
        "    predictions = [predict(user, book) for user, book in zip(user_ids, book_ids)]\n",
        "    mse = np.mean((np.array(predictions) - np.array(actual_ratings)) ** 2)\n",
        "    mae = np.mean(np.abs(np.array(predictions) - np.array(actual_ratings)))\n",
        "    return mse, mae\n",
        "\n",
        "# Evaluate the model\n",
        "user_ids, book_ids, ratings = prepare_data(load_books_from_db())  # Ensure the data is prepared and loaded\n",
        "mse, mae = evaluate_model(user_ids, book_ids, ratings)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3axWjksKc5Q",
        "outputId": "aaea5caf-0950-40ad-dc54-e2a8e4dcdc1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 1 and book 1: 0.2561124563217163\n",
            "Predicted rating for user 2 and book 2: 0.16438691318035126\n",
            "Mean Squared Error: 8.831287821240185\n",
            "Mean Absolute Error: 2.9020858142524957\n"
          ]
        }
      ]
    }
  ]
}